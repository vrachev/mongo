stepback: false
command_type: system

variables:
  ###
  # Leave this section uncommented to enable compile.
  _real_compile_amazon2: &_compile_amazon2
      - name: compile
        variant: compile-amazon2
      - name: genny_generate_all_tasks
        variant: compile-amazon2
  _real_compile_rhel70: &_compile_rhel70
      - name: compile
        variant: compile-rhel70
      - name: genny_generate_all_tasks
        variant: compile-amazon2
  _real_expansions: &_expansion_updates
    []
  ###

###
# **Or**: Leave this section uncommented to bypass/skip compile.
#  _skip_compile_amazon2: &_compile_amazon2
#      - name: genny_generate_all_tasks
#        variant: compile-amazon2
#  _skip_compile_rhel70: &_compile_rhel70
#      - name: genny_generate_all_tasks
#        variant: compile-amazon2
#  _skip_expansions: &_expansion_updates
#      # This is the normal (amazon2) "compile" artifact from https://evergreen.mongodb.com/version/sys_perf_4.4_78207ca380688c73b1a217f23d5b7c8803bef9cd
#      - key: mdb_binary_for_client
#        value: https://dsi-donot-remove.s3-us-west-2.amazonaws.com/compile_artifacts/mongodb-sys_perf_4.4_78207ca380688c73b1a217f23d5b7c8803bef9cd.tar.gz
#      - key: mdb_binary_for_server
#        value: https://dsi-donot-remove.s3-us-west-2.amazonaws.com/compile_artifacts/mongodb-sys_perf_4.4_78207ca380688c73b1a217f23d5b7c8803bef9cd.tar.gz
###

  _src_dir: &src_dir src/mongo
  _modules: &modules
    - dsi
    - genny
    - signal-processing
    - workloads
    - linkbench
    - linkbench2
    - mongo-perf
    - YCSB
    - benchmarks
    - py-tpcc

modules:
###
# Same in every DSI project
- name: dsi
  repo: git@github.com:10gen/dsi.git
  prefix: ../../src
  branch: master
- name: genny
  repo: git@github.com:10gen/genny.git
  prefix: ../../src
  branch: master
- name: signal-processing
  repo: git@github.com:10gen/signal-processing.git
  prefix: ../../src
  branch: master
- name: workloads
  repo: git@github.com:10gen/workloads.git
  prefix: ../../src
  branch: master
- name: linkbench
  repo: git@github.com:10gen/linkbench.git
  prefix: ../../src
  branch: master
- name: linkbench2
  repo: git@github.com:10gen/linkbench2.git
  prefix: ../../src
  branch: master
- name: mongo-perf
  repo: git@github.com:mongodb/mongo-perf.git
  prefix: ../../src
  branch: master
- name: YCSB
  repo: git@github.com:mongodb-labs/YCSB.git
  prefix: ../../src
  branch: master
  ref: 4e7287880c04514cad2df5761b9511c940a33059
- name: benchmarks
  repo: git@github.com:mongodb-labs/benchmarks.git
  prefix: ../../src
  branch: master
- name: py-tpcc
  repo: git@github.com:mongodb-labs/py-tpcc.git
  prefix: ../../src
  branch: master
  ref: 2d19705337a40e24831a904266a648b85df5be84


###
# Same in every DSI project
pre:
    - func: "f_other_pre_ops"
    - func: "f_dsi_pre_run"
post:
    - func: "f_dsi_post_run"
    - func: "f_other_post_ops"
###


functions:
  ###
  # Same in every DSI project
  "f_dsi_pre_run":
    - command: manifest.load
    - command: expansions.update
      params:
        updates: *_expansion_updates
  "f_run_dsi_workload":
    - command: shell.exec
      params:
        script: |
          rm -rf ./*
          mkdir src
    - command: manifest.load
    - command: git.get_project
      params:
        directory: *src_dir
        revisions: &revisions_list
          dsi: ${dsi_rev}
          genny: ${genny_rev}
          signal-processing: ${signal-processing_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          workloads: ${workloads_rev}
          mongo-perf: ${mongo-perf_rev}
          YCSB: ${YCSB_rev}
          benchmarks: ${benchmarks_rev}
          py-tpcc: ${py-tpcc_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        continue_on_err: true
        script: ./src/dsi/run-dsi run_workload
    - command: shell.exec
      type: system
      params:
        script: ./src/dsi/run-dsi determine_failure -m SYSTEM
    - command: shell.exec
      type: setup
      params:
        script: ./src/dsi/run-dsi determine_failure -m SETUP
    - command: shell.exec
      type: test
      params:
        script: ./src/dsi/run-dsi determine_failure -m TEST
    - command: shell.exec
      type: test
      params:
        script: |
          ./src/dsi/run-dsi analysis
          # detect outliers needs to run, so defer the post_run_check exit status to later
          echo $? > post_run_check.status
    - command: json.send
      params:
        name: "perf"
        file: "./build/LegacyPerfJson/perf.json"
    - command: shell.exec
      params:
        script: |
          set -o errexit
          is_patch=${is_patch}
          task_id=${task_id}
          perf_jira_user=${perf_jira_user}
          perf_jira_pw=${perf_jira_pw}
          analysis_user=${dsi_analysis_atlas_user}
          analysis_password=${dsi_analysis_atlas_pw}
          evergreen_api_key=${evergreen_api_key}
          evergreen_api_user=${evergreen_api_user}
          source ./src/dsi/src/signal_processing_setup.sh
    - command: shell.exec
      params:
        script: |
          set -o verbose
          source ./signal_processing_venv/bin/activate
          detect-changes --config .signal-processing.yml --mongo-repo=./src/mongo
    - command: shell.exec
      type: test
      params:
        script: |
          set -o verbose
          exit $(cat post_run_check.status)
  "f_dsi_post_run":
      - command: shell.exec
        params:
          script: ./src/dsi/run-dsi infrastructure_teardown
      - command: shell.exec
        params:
          script: ./src/dsi/run-dsi ./src/dsi/src/dsi/make_artifact.sh
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: dsi-artifacts.tgz
          remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/dsi-artifacts-${task_name}-${build_id}-${execution}.${ext|tgz}
          bucket: mciuploads
          permissions: public-read
          content_type: ${content_type|application/x-gzip}
          display_name: Dsi Artifacts - Execution ${execution}
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: src/mongo/workloads/workloads/jsdoc/jsdocs-redirect.html
          remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/workloads-${task_name}-${build_id}.html
          bucket: mciuploads
          permissions: public-read
          content_type: text/html
          display_name: workloads documentation
      - command: attach.results
        params:
          file_location: report.json
      - command: json.send
        params:
          name: "perf"
          file: "./build/LegacyPerfJson/perf.json"
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: pip-requirements.txt
          remote_file: ${project}/${build_variant}/${revision}/pip-requirements-${task_id}-${execution}.txt
          bucket: mciuploads
          permissions: public-read
          content_type: atext-plain
          display_name: Pip Requirements
  ###


  "f_other_post_ops":
      - command: shell.exec
        params:
          working_dir: src
          script: |
            # removes files from the (local) scons cache when it's over a
            # threshold, to the $prune_ratio percentage. Ideally override
            # these default values in the distro config in evergreen.
            if [ -d "${scons_cache_path}" ]; then
                /opt/mongodbtoolchain/v3/bin/python3 buildscripts/scons_cache_prune.py --cache-dir ${scons_cache_path} --cache-size ${scons_cache_size|200} --prune-ratio ${scons_prune_ratio|0.8}
            fi
  "f_other_pre_ops":
    - &f_other_pre_ops
      command: shell.exec
      params:
        silent: true
        script: |
          for PS in mongo{,d,s,import,export,dump,restore,stat,files,top,bridge} resmoke.py python{,2} lldb _test; do
              pkill -9 "$PS"
          done

  ###
  # Compile
  "compile mongodb":
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          # We get the raw version string (r1.2.3-45-gabcdef) from git
          MONGO_VERSION=$(git describe)
          # If we're going to compile the upstream wtdevelop repository for wiredtiger, add
          # that githash to version string.
          if [ "${wtdevelop|}" = "-wtdevelop" ]; then
            WT_VERSION=$(cd src/third_party/wtdevelop; git describe | cut -c 9-)
            MONGO_VERSION="$MONGO_VERSION-wtdevelop-$WT_VERSION"
          fi
          # If this is a patch build, we add the patch version id to the version string so we know
          # this build was a patch, and which evergreen task it came from
          if [ "${is_patch|}" = "true" ]; then
            MONGO_VERSION="$MONGO_VERSION-patch-${version_id}"
          fi

          # This script converts the generated version string into a sanitized version string for
          # use by scons and uploading artifacts as well as information about for the scons cache.
          MONGO_VERSION=$MONGO_VERSION USE_SCONS_CACHE=${use_scons_cache|false} ${python|/opt/mongodbtoolchain/v2/bin/python2} buildscripts/generate_compile_expansions.py --out compile_expansions.yml
    # Then we load the generated version data into the agent so we can use it in task definitions
    - command: expansions.update
      params:
        file: src/compile_expansions.yml
    - command: shell.exec
      params:
        working_dir: src/src/mongo/gotools/src/github.com/mongodb/mongo-tools
        script: |
          set -o verbose
          set -o errexit
          # make sure newlines in the scripts are handled correctly by windows
          if [ "Windows_NT" = "$OS" ]; then
            set -o igncr
          fi;
          # set_goenv provides set_goenv(), print_ldflags() and print_tags() used below
          . ./set_goenv.sh
          GOROOT="" set_goenv || exit
          go version
          build_tools="bsondump mongostat mongofiles mongoexport mongoimport mongorestore mongodump mongotop"
          if [ "${build_mongoreplay}" = "true" ]; then
              build_tools="$build_tools mongoreplay"
          fi
          for i in $build_tools; do
              go build -ldflags "$(print_ldflags)" ${args} -tags "$(print_tags ${tooltags})" -o "../../../../../../mongo-tools/$i${exe|}" $i/main/$i.go
              "../../../../../../mongo-tools/$i${exe|}" --version
          done
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          ${python|/opt/mongodbtoolchain/v2/bin/python2} ./buildscripts/scons.py ${compile_flags|} ${scons_cache_args|} mongo${extension} --use-new-tools mongod${extension} mongos${extension} MONGO_VERSION=${version}
          mkdir -p mongodb/bin
          mkdir -p mongodb/jstests/hooks
          mv mongo${extension|} mongodb/bin
          mv mongod${extension|} mongodb/bin
          mv mongos${extension|} mongodb/bin
          mv src/mongo-tools/* mongodb/bin
          if [ -d jstests/hooks ]
          then
            echo "Fetching JS test DB correctness checks from directory jstests"
            cp -a jstests/* mongodb/jstests

            echo "Now adding our own special run_validate_collections.js wrapper"
            mv mongodb/jstests/hooks/run_validate_collections.js mongodb/jstests/hooks/run_validate_collections.actual.js

            cat << EOF > mongodb/jstests/hooks/run_validate_collections.js
            print("NOTE: run_validate_collections.js will skip the oplog!");
            TestData = { skipValidationNamespaces: ['local.oplog.rs'] };
            load('jstests/hooks/run_validate_collections.actual.js');
          EOF
          fi
          tar czf mongodb${wtdevelop|}.tar.gz mongodb
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb${wtdevelop|}.tar.gz
        remote_file: ${project_dir}/${version_id}/${revision}/${platform}/mongodb${wtdevelop|}-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb${wtdevelop|}.tar.gz



pre:

post:
    # Do cluster teardown first to ensure runtime is below Evergreen's post timeout. Other post tasks
    # will not have been run if the timeout is exceeded.
    - command: shell.exec
      params:
        working_dir: work
        script: |
          source ./dsienv.sh
          if [ -e /data/infrastructure_provisioning/terraform/provisioned.${cluster} ]; then
            mark_idle.sh
          fi
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          set -v
          source ./dsienv.sh
          ../src/dsi/dsi/run-dsi infrastructure_teardown.py
    - command: shell.exec
      params:
        working_dir: work
        script: |
          source ./dsienv.sh
          make_artifact.sh
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: work/dsi-artifacts.tgz
        remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/dsi-artifacts-${task_name}-${build_id}-${execution}.${ext|tgz}
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: Dsi Artifacts - Execution ${execution}
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/workloads/workloads/jsdoc/jsdocs-redirect.html
        remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/workloads-${task_name}-${build_id}.html
        bucket: mciuploads
        permissions: public-read
        content_type: text/html
        display_name: workloads documentation
    - command: attach.results
      params:
        file_location: work/report.json
    - command: "json.send"
      params:
         name: "perf"
         file: "work/perf.json"
    - command: shell.exec
      params:
        working_dir: src
        script: |
          # removes files from the (local) scons cache when it's over a
          # threshold, to the $prune_ratio percentage. Ideally override
          # these default values in the distro config in evergreen.

          if [ -d "${scons_cache_path}" ]; then
              ${python|/opt/mongodbtoolchain/v2/bin/python2} buildscripts/scons_cache_prune.py --cache-dir ${scons_cache_path} --cache-size ${scons_cache_size|200} --prune-ratio ${scons_prune_ratio|0.8}
          fi

functions:
  "compile mongodb":
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          # We get the raw version string (r1.2.3-45-gabcdef) from git
          MONGO_VERSION=$(git describe)
          # If we're going to compile the upstream wtdevelop repository for wiredtiger, add
          # that githash to version string.
          if [ "${wtdevelop|}" = "-wtdevelop" ]; then
            WT_VERSION=$(cd src/third_party/wtdevelop; git describe | cut -c 9-)
            MONGO_VERSION="$MONGO_VERSION-wtdevelop-$WT_VERSION"
          fi
          # If this is a patch build, we add the patch version id to the version string so we know
          # this build was a patch, and which evergreen task it came from
          if [ "${is_patch|}" = "true" ]; then
            MONGO_VERSION="$MONGO_VERSION-patch-${version_id}"
          fi

          # This script converts the generated version string into a sanitized version string for
          # use by scons and uploading artifacts as well as information about for the scons cache.
          MONGO_VERSION=$MONGO_VERSION USE_SCONS_CACHE=${use_scons_cache|false} ${python|/opt/mongodbtoolchain/v2/bin/python2} buildscripts/generate_compile_expansions.py --out compile_expansions.yml
    # Then we load the generated version data into the agent so we can use it in task definitions
    - command: expansions.update
      params:
        file: src/compile_expansions.yml
    - command: shell.exec
      params:
        working_dir: src/src/mongo/gotools/src/github.com/mongodb/mongo-tools
        script: |
          set -o verbose
          set -o errexit
          # make sure newlines in the scripts are handled correctly by windows
          if [ "Windows_NT" = "$OS" ]; then
            set -o igncr
          fi;
          # set_goenv provides set_goenv(), print_ldflags() and print_tags() used below
          . ./set_goenv.sh
          GOROOT="" set_goenv || exit
          go version
          build_tools="bsondump mongostat mongofiles mongoexport mongoimport mongorestore mongodump mongotop"
          if [ "${build_mongoreplay}" = "true" ]; then
              build_tools="$build_tools mongoreplay"
          fi
          for i in $build_tools; do
              go build -ldflags "$(print_ldflags)" ${args} -tags "$(print_tags ${tooltags})" -o "../../../../../../mongo-tools/$i${exe|}" $i/main/$i.go
              "../../../../../../mongo-tools/$i${exe|}" --version
          done
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          ${python|/opt/mongodbtoolchain/v2/bin/python2} ./buildscripts/scons.py ${compile_flags|} ${scons_cache_args|} mongo${extension} --use-new-tools mongod${extension} mongos${extension} MONGO_VERSION=${version}
          mkdir -p mongodb/bin
          mkdir -p mongodb/jstests/hooks
          mv mongo${extension|} mongodb/bin
          mv mongod${extension|} mongodb/bin
          mv mongos${extension|} mongodb/bin
          mv src/mongo-tools/* mongodb/bin
          if [ -d jstests/hooks ]
          then
            echo "Fetching JS test DB correctness checks from directory jstests"
            cp -a jstests/* mongodb/jstests

            echo "Now adding our own special run_validate_collections.js wrapper"
            mv mongodb/jstests/hooks/run_validate_collections.js mongodb/jstests/hooks/run_validate_collections.actual.js

            cat << EOF > mongodb/jstests/hooks/run_validate_collections.js
            print("NOTE: run_validate_collections.js will skip the oplog!");
            TestData = { skipValidationNamespaces: ['local.oplog.rs'] };
            load('jstests/hooks/run_validate_collections.actual.js');
          EOF
          fi
          tar czf mongodb${wtdevelop|}.tar.gz mongodb
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb${wtdevelop|}.tar.gz
        remote_file: ${project_dir}/${version_id}/${revision}/${platform}/mongodb${wtdevelop|}-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb${wtdevelop|}.tar.gz

  # NOTE: Unlike evergreen.yml, there's no conditional here. If called, this is never a noop!
  "use WiredTiger develop" :
    command: shell.exec
    params:
      working_dir: src
      script: |
        set -o errexit
        set -o verbose
        cd src/third_party
        for wtdir in api dist examples ext lang src test tools ; do
          rm -rf wiredtiger/$wtdir
          mv wtdevelop/$wtdir wiredtiger/
        done

  "prepare environment":
    - command: shell.exec
      params:
        script: |
          rm -rf ./*
          mkdir src
          mkdir work
    - command: manifest.load
    - command: git.get_project
      params:
        directory: src
        revisions: # for each module include revision as <module_name> : ${<module_name>_rev}
          dsi: ${dsi_rev}
          workloads: ${workloads_rev}
    - command: shell.exec
      params:
        working_dir: work
        script: |
          cat > bootstrap.yml <<EOF
          infrastructure_provisioning: ${cluster}
          platform: ${platform}
          mongodb_setup: ${setup}
          storageEngine: ${storageEngine}
          test_control: ${test}
          production: true
          overrides:
            infrastructure_provisioning:
              tfvars:
                # This is currently only used by initialsync-logkeeper. It is empty and not used for other tests.
                mongod_seeded_ebs_snapshot_id: ${snapshotId}
            workload_setup:
              local_repos:
                workloads: ../src/workloads/workloads
                ycsb: ../src/YCSB/YCSB
            mongodb_setup:
              mongodb_binary_archive: "https://s3.amazonaws.com/mciuploads/${project_dir}/${version_id}/${revision}/${platform}/mongodb${wtdevelop|}-${version_id}.tar.gz"
          EOF

          cat > runtime.yml <<EOF
          # evergreen default expansions
          is_patch: ${is_patch}
          order: ${revision_order_id}
          task_id: ${task_id}
          task_name: ${task_name}
          execution: ${execution}
          build_id: ${build_id}
          build_variant: ${build_variant}
          version_id: ${version_id}
          workdir: ${workdir}
          revision: ${revision}
          project_dir: ${project_dir}
          branch_name: ${branch_name}
          project: ${project}

          # sys-perf expansions
          # Shouldn't be needed: testList: ${testList}
          ext: ${ext}
          script_flags : ${script_flags}
          dsi_rev: ${dsi_rev}
          workloads_rev: ${workloads_rev}
          EOF

    - command: shell.exec
      params:
        silent: true
        working_dir: work
        script: |
          # AWS ssh secret key
          echo "${ec2_pem}" > aws_ssh_key.pem
          chmod 400 aws_ssh_key.pem

          cat > runtime_secret.yml <<EOF
          # Note that inside system_perf.yml we have ${aws_key} & ${aws_secret}, which are used for
          # Evergreen resources. The below are used for dsi resources, and are NOT the same!
          aws_access_key: "${terraform_key}"
          aws_secret_key: "${terraform_secret}"
          perf_jira_user: "${perf_jira_user}"
          perf_jira_pw: "${perf_jira_pw}"
          dsi_analysis_atlas_user: "${dsi_analysis_atlas_user}"
          dsi_analysis_atlas_pw: "${dsi_analysis_atlas_pw}"
          EOF
          chmod 400 runtime_secret.yml
    - command: shell.exec
      params:
        working_dir: work
        # setup execution environment
        # configure environment, has private information, no logging
        script: |
          set -e
          ../src/dsi/dsi/run-dsi python ../src/dsi/dsi/bin/bootstrap.py
    - command: shell.exec
      params:
        script: |
          set -v
          set -e
          source work/dsienv.sh
          setup-dsi-env.sh
          ls -a work

  "deploy cluster":
    - command: shell.exec
      params:
        working_dir: work
        script: |
          set -e
          set -v
          source ./dsienv.sh
          ../src/dsi/dsi/run-dsi infrastructure_provisioning.py
          ../src/dsi/dsi/run-dsi workload_setup.py
          ../src/dsi/dsi/run-dsi mongodb_setup.py

  "run test":
    - command: shell.exec
      type: test
      params:
        working_dir: work
        script: |
          set -e
          set -v
          source ./dsienv.sh
          ../src/dsi/dsi/run-dsi test_control.py
    - command: "json.send"
      params:
         name: "perf"
         file: "work/perf.json"

  "analyze":
    - command: shell.exec
      type: test
      params:
        working_dir: work
        script: |
          set -o verbose
          source ./dsienv.sh
          ../src/dsi/dsi/run-dsi analysis.py
          # detect outliers needs to run, so defer the post_run_check exit status to later
          echo $? > post_run_check.status
    - command: shell.exec
      params:
        working_dir: work
        script: |
          is_patch=${is_patch}
          task_id=${task_id}
          perf_jira_user=${perf_jira_user}
          perf_jira_pw=${perf_jira_pw}
          dsi_analysis_atlas_user=${dsi_analysis_atlas_user}
          dsi_analysis_atlas_pw=${dsi_analysis_atlas_pw}
          evergreen_api_key=${evergreen_api_key}
          evergreen_api_user=${evergreen_api_user}
          source ../src/buildscripts/signal_processing_setup.sh
          detect-changes --config .signal-processing.yml

#######################################
#               Tasks                 #
#######################################

tasks:
- name: compile
  commands:
    - command: manifest.load
    - command: git.get_project
      params:
        directory: src
    - func: "compile mongodb"

- name: industry_benchmarks
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "ycsb"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: industry_benchmarks_secondary_reads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "ycsb-secondary-reads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: industry_benchmarks_wmajority
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "ycsb-wmajority"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"
      vars:
        script_flags: --ycsb-throughput-analysis reports

- name: crud_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "crud_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: mixed_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "mixed_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: misc_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "misc_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: map_reduce_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "map_reduce_workloads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: smoke_test
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "short"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: retryable_writes_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "retryable_writes"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: snapshot_reads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "snapshot_reads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: secondary_reads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "secondary_reads"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: bestbuy_agg
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "bestbuy_agg"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: bestbuy_query
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "bestbuy_query"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: non_sharded_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "non_sharded"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: mongos_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "mongos"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: move_chunk_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "move_chunk"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: move_chunk_waiting_workloads
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "move_chunk_waiting"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: secondary_performance
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        # Unfortunately the dash/underscore style is different for mongodb_setup and test_control
        test: "secondary_performance"
        setup: "secondary-performance"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: initialsync
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "initialsync"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: initialsync-logkeeper
  priority: 5
  exec_timeout_secs: 216000 # 2.5 days
  commands:
    - func: "prepare environment"
      vars:
        test: "initialsync-logkeeper"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: change_streams_throughput
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "change_streams_throughput"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: change_streams_latency
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "change_streams_latency"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"

- name: change_streams_multi_mongos
  priority: 5
  commands:
    - func: "prepare environment"
      vars:
        test: "change_streams_multi_mongos"
    - func: "deploy cluster"
    - func: "run test"
    - func: "analyze"


#######################################
#         Buildvariants               #
#######################################
buildvariants:

# We are explicitly tracking the rhel70 variant compile options from evergreen.yml.  If we can get
# proper artifacts directly from that project, we should do that and remove these tasks.
- name: compile-rhel70
  display_name: Compile on rhel70
  modules:
    - wtdevelop
  expansions:
    compile_flags: --ssl MONGO_DISTMOD=rhel70 -j$(grep -c ^processor /proc/cpuinfo) --release --variables-files=etc/scons/mongodbtoolchain_gcc.vars
    platform: linux
    project_dir: &project_dir dsi
    tooltags: ""
    use_scons_cache: true
  run_on:
      - "rhel70"
  tasks:
    - name: compile


#######################################
#         Linux Buildvariants         #
#######################################
- name: linux-1-node-replSet
  display_name: Linux 1-Node ReplSet
  modules: &modules
    - dsi
    - workloads
    - signal-processing
  expansions:
    setup: single-replica
    cluster: single
    platform: linux
    project_dir: *project_dir
    storageEngine: wiredTiger
  run_on:
      - "rhel70-perf-single"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks: &1nodetasks
    - name: industry_benchmarks
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: smoke_test
    - name: retryable_writes_workloads
    - name: non_sharded_workloads
    - name: bestbuy_agg
    - name: bestbuy_query
    - name: change_streams_throughput
    - name: change_streams_latency

- name: linux-standalone
  display_name: Linux Standalone
  modules: *modules
  expansions:
    setup: standalone
    cluster: single
    platform: linux
    project_dir: *project_dir
    storageEngine: wiredTiger
  run_on:
      - "rhel70-perf-single"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks: &standalonetasks
    - name: industry_benchmarks
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: smoke_test
    - name: non_sharded_workloads
    - name: bestbuy_agg
    - name: bestbuy_query

- name: linux-3-shard
  display_name: Linux 3-Shard Cluster
  modules: *modules
  expansions:
    setup: shard
    cluster: shard
    platform: linux
    project_dir: *project_dir
    storageEngine: wiredTiger
  run_on:
      - "rhel70-perf-shard"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: industry_benchmarks
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: smoke_test
    - name: retryable_writes_workloads
    - name: industry_benchmarks_wmajority
    - name: mongos_workloads
    - name: move_chunk_workloads
    - name: move_chunk_waiting_workloads
    - name: bestbuy_agg
    - name: bestbuy_query
    - name: change_streams_throughput
    - name: change_streams_latency
    - name: change_streams_multi_mongos

- name: linux-3-node-replSet
  display_name: Linux 3-Node ReplSet
  modules: *modules
  expansions:
    setup: replica
    cluster: replica
    platform: linux
    project_dir: *project_dir
    storageEngine: wiredTiger
  run_on:
      - "rhel70-perf-replset"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks: &3nodetasks
    - name: industry_benchmarks
    - name: industry_benchmarks_secondary_reads
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: smoke_test
    - name: retryable_writes_workloads
    - name: industry_benchmarks_wmajority
    - name: secondary_performance
    - name: non_sharded_workloads
    - name: bestbuy_agg
    - name: bestbuy_query
    - name: change_streams_throughput
    - name: change_streams_latency
    - name: secondary_reads

- name: linux-3-node-replSet-initialsync
  display_name: Linux 3-Node ReplSet Initial Sync
  modules: *modules
  expansions:
    setup: replica-2node
    cluster: replica
    platform: linux
    storageEngine: wiredTiger
    project_dir: *project_dir
  run_on:
      - "rhel70-perf-replset"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: initialsync


- name: linux-replSet-initialsync-logkeeper
  display_name: Linux ReplSet Initial Sync LogKeeper
  modules: *modules
  expansions:
    setup: initialsync-logkeeper
    cluster: initialsync-logkeeper
    # EBS logkeeper snapshot with FCV set to 4.0
    snapshotId: snap-044cc4cf3f616ef5d
    platform: linux
    # TODO(TIG-1506): enabled authentication on initialsync variants
    authentication: disabled
    storageEngine: wiredTiger
    project_dir: *project_dir
  run_on:
      - "rhel70-perf-initialsync-logkeeper"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: initialsync-logkeeper

#######################################
#         MMAP Buildvariants         #
#######################################
- name: mmap-1-node-replSet
  display_name: MMAP 1-Node ReplSet
  modules: *modules
  expansions:
    setup: single-replica
    cluster: single
    platform: linux
    storageEngine: "mmapv1"
    project_dir: *project_dir
  run_on:
      - "rhel70-perf-single"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: smoke_test
    - name: industry_benchmarks
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: non_sharded_workloads
    - name: bestbuy_agg
    - name: bestbuy_query

- name: mmap-standalone
  display_name: MMAP Standalone
  modules: *modules
  expansions:
    setup: standalone
    cluster: single
    platform: linux
    storageEngine: "mmapv1"
    project_dir: *project_dir
  run_on:
      - "rhel70-perf-single"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: smoke_test
    - name: industry_benchmarks
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: non_sharded_workloads
    - name: bestbuy_agg
    - name: bestbuy_query

- name: mmap-3-shard
  display_name: MMAP 3-Shard Cluster
  modules: *modules
  expansions:
    setup: shard
    cluster: shard
    platform: linux
    project_dir: *project_dir
    storageEngine: "mmapv1"
  run_on:
      - "rhel70-perf-shard"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: smoke_test
    - name: industry_benchmarks
    - name: industry_benchmarks_wmajority
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: mongos_workloads
    - name: move_chunk_workloads
    - name: bestbuy_agg
    - name: bestbuy_query

- name: mmap-3-node-replSet
  display_name: MMAP 3-Node ReplSet
  modules: *modules
  expansions:
    setup: replica
    cluster: replica
    platform: linux
    storageEngine: "mmapv1"
    project_dir: *project_dir
  run_on:
      - "rhel70-perf-replset"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: smoke_test
    - name: industry_benchmarks
    - name: industry_benchmarks_wmajority
    - name: crud_workloads
    - name: mixed_workloads
    - name: misc_workloads
    - name: map_reduce_workloads
    - name: secondary_performance
    - name: non_sharded_workloads
    - name: bestbuy_agg
    - name: bestbuy_query

- name: mmap-3-node-replSet-initialsync
  display_name: MMAP 3-Node ReplSet Initial Sync
  modules: *modules
  expansions:
    setup: replica-2node
    cluster: replica
    platform: linux
    storageEngine: "mmapv1"
    project_dir: *project_dir
  run_on:
      - "rhel70-perf-replset"
  depends_on:
      - name: compile
        variant: compile-rhel70
  tasks:
    - name: initialsync
